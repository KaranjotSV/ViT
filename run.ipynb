{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvMFmvieJEKK",
        "outputId": "03e3d91d-a2b4-4724-c66b-7863ca73ca68"
      },
      "id": "KvMFmvieJEKK",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.16.1)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "  Attempting uninstall: tensorflow-addons\n",
            "    Found existing installation: tensorflow-addons 0.16.1\n",
            "    Uninstalling tensorflow-addons-0.16.1:\n",
            "      Successfully uninstalled tensorflow-addons-0.16.1\n",
            "Successfully installed tensorflow-addons-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "72b255d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72b255d7",
        "outputId": "233e8cd7-ef86-4895-e512-23ab2183253e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training: (50000, 32, 32, 3) - labels: (50000, 1)\n",
            "testing: (10000, 32, 32, 3) - labels: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "from model import create_ViT, run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dba2dea5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dba2dea5",
        "outputId": "f085e3ab-1805-435b-b885-75166703fe3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training - SPT: False, LSA: False, MASKING: False, TRAIN_TAU: False\n",
            "Epoch 1/20\n",
            "176/176 [==============================] - 164s 854ms/step - loss: 4.5284 - accuracy: 0.0352 - top-5-accuracy: 0.1326 - val_loss: 4.0225 - val_accuracy: 0.0868 - val_top-5-accuracy: 0.2756\n",
            "Epoch 2/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 4.0598 - accuracy: 0.0766 - top-5-accuracy: 0.2538 - val_loss: 3.7383 - val_accuracy: 0.1328 - val_top-5-accuracy: 0.3670\n",
            "Epoch 3/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 3.8313 - accuracy: 0.1084 - top-5-accuracy: 0.3269 - val_loss: 3.5184 - val_accuracy: 0.1720 - val_top-5-accuracy: 0.4436\n",
            "Epoch 4/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 3.6493 - accuracy: 0.1399 - top-5-accuracy: 0.3807 - val_loss: 3.3592 - val_accuracy: 0.1982 - val_top-5-accuracy: 0.4790\n",
            "Epoch 5/20\n",
            "176/176 [==============================] - 149s 845ms/step - loss: 3.5026 - accuracy: 0.1651 - top-5-accuracy: 0.4217 - val_loss: 3.1384 - val_accuracy: 0.2278 - val_top-5-accuracy: 0.5244\n",
            "Epoch 6/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 3.3759 - accuracy: 0.1884 - top-5-accuracy: 0.4592 - val_loss: 3.0291 - val_accuracy: 0.2468 - val_top-5-accuracy: 0.5528\n",
            "Epoch 7/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 3.2588 - accuracy: 0.2079 - top-5-accuracy: 0.4867 - val_loss: 2.9799 - val_accuracy: 0.2686 - val_top-5-accuracy: 0.5662\n",
            "Epoch 8/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 3.1561 - accuracy: 0.2256 - top-5-accuracy: 0.5152 - val_loss: 2.8167 - val_accuracy: 0.2872 - val_top-5-accuracy: 0.6010\n",
            "Epoch 9/20\n",
            "176/176 [==============================] - 149s 845ms/step - loss: 3.0342 - accuracy: 0.2489 - top-5-accuracy: 0.5458 - val_loss: 2.7205 - val_accuracy: 0.3148 - val_top-5-accuracy: 0.6262\n",
            "Epoch 10/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 2.9384 - accuracy: 0.2685 - top-5-accuracy: 0.5700 - val_loss: 2.6662 - val_accuracy: 0.3174 - val_top-5-accuracy: 0.6322\n",
            "Epoch 11/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 2.8425 - accuracy: 0.2863 - top-5-accuracy: 0.5895 - val_loss: 2.5575 - val_accuracy: 0.3494 - val_top-5-accuracy: 0.6508\n",
            "Epoch 12/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 2.7498 - accuracy: 0.3016 - top-5-accuracy: 0.6136 - val_loss: 2.4895 - val_accuracy: 0.3500 - val_top-5-accuracy: 0.6698\n",
            "Epoch 13/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 2.6561 - accuracy: 0.3200 - top-5-accuracy: 0.6348 - val_loss: 2.4809 - val_accuracy: 0.3622 - val_top-5-accuracy: 0.6644\n",
            "Epoch 14/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 2.5891 - accuracy: 0.3341 - top-5-accuracy: 0.6492 - val_loss: 2.3578 - val_accuracy: 0.3818 - val_top-5-accuracy: 0.7004\n",
            "Epoch 15/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 2.5020 - accuracy: 0.3542 - top-5-accuracy: 0.6694 - val_loss: 2.3066 - val_accuracy: 0.3864 - val_top-5-accuracy: 0.7122\n",
            "Epoch 16/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 2.4455 - accuracy: 0.3664 - top-5-accuracy: 0.6810 - val_loss: 2.2783 - val_accuracy: 0.4012 - val_top-5-accuracy: 0.7156\n",
            "Epoch 17/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 2.3717 - accuracy: 0.3817 - top-5-accuracy: 0.6959 - val_loss: 2.2359 - val_accuracy: 0.4148 - val_top-5-accuracy: 0.7206\n",
            "Epoch 18/20\n",
            "176/176 [==============================] - 149s 845ms/step - loss: 2.3066 - accuracy: 0.3955 - top-5-accuracy: 0.7088 - val_loss: 2.1609 - val_accuracy: 0.4252 - val_top-5-accuracy: 0.7354\n",
            "Epoch 19/20\n",
            "176/176 [==============================] - 149s 845ms/step - loss: 2.2543 - accuracy: 0.4064 - top-5-accuracy: 0.7214 - val_loss: 2.1154 - val_accuracy: 0.4374 - val_top-5-accuracy: 0.7424\n",
            "Epoch 20/20\n",
            "176/176 [==============================] - 149s 845ms/step - loss: 2.1875 - accuracy: 0.4219 - top-5-accuracy: 0.7354 - val_loss: 2.0907 - val_accuracy: 0.4410 - val_top-5-accuracy: 0.7504\n",
            "313/313 [==============================] - 17s 56ms/step - loss: 2.0583 - accuracy: 0.4505 - top-5-accuracy: 0.7588\n",
            "test accuracy: 45.05\n",
            "test top 5 accuracy: 75.88\n",
            "training - SPT: False, LSA: True, MASKING: False, TRAIN_TAU: True\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "176/176 [==============================] - 164s 857ms/step - loss: 4.5111 - accuracy: 0.0378 - top-5-accuracy: 0.1406 - val_loss: 3.9969 - val_accuracy: 0.0912 - val_top-5-accuracy: 0.2866\n",
            "Epoch 2/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 4.0310 - accuracy: 0.0788 - top-5-accuracy: 0.2590 - val_loss: 3.7099 - val_accuracy: 0.1466 - val_top-5-accuracy: 0.3870\n",
            "Epoch 3/20\n",
            "176/176 [==============================] - 149s 845ms/step - loss: 3.7959 - accuracy: 0.1174 - top-5-accuracy: 0.3339 - val_loss: 3.4721 - val_accuracy: 0.1772 - val_top-5-accuracy: 0.4454\n",
            "Epoch 4/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 3.6282 - accuracy: 0.1430 - top-5-accuracy: 0.3862 - val_loss: 3.3045 - val_accuracy: 0.2214 - val_top-5-accuracy: 0.4904\n",
            "Epoch 5/20\n",
            "176/176 [==============================] - 149s 845ms/step - loss: 3.4902 - accuracy: 0.1654 - top-5-accuracy: 0.4246 - val_loss: 3.1374 - val_accuracy: 0.2400 - val_top-5-accuracy: 0.5248\n",
            "Epoch 6/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 3.3593 - accuracy: 0.1885 - top-5-accuracy: 0.4593 - val_loss: 3.0085 - val_accuracy: 0.2658 - val_top-5-accuracy: 0.5612\n",
            "Epoch 7/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 3.2382 - accuracy: 0.2146 - top-5-accuracy: 0.4939 - val_loss: 2.8880 - val_accuracy: 0.2870 - val_top-5-accuracy: 0.5880\n",
            "Epoch 8/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 3.1135 - accuracy: 0.2339 - top-5-accuracy: 0.5227 - val_loss: 2.7838 - val_accuracy: 0.2986 - val_top-5-accuracy: 0.6132\n",
            "Epoch 9/20\n",
            "176/176 [==============================] - 149s 845ms/step - loss: 2.9990 - accuracy: 0.2524 - top-5-accuracy: 0.5525 - val_loss: 2.6608 - val_accuracy: 0.3258 - val_top-5-accuracy: 0.6362\n",
            "Epoch 10/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 2.8740 - accuracy: 0.2781 - top-5-accuracy: 0.5837 - val_loss: 2.6311 - val_accuracy: 0.3280 - val_top-5-accuracy: 0.6342\n",
            "Epoch 11/20\n",
            "176/176 [==============================] - 149s 845ms/step - loss: 2.7712 - accuracy: 0.2978 - top-5-accuracy: 0.6075 - val_loss: 2.5375 - val_accuracy: 0.3460 - val_top-5-accuracy: 0.6550\n",
            "Epoch 12/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 2.6887 - accuracy: 0.3137 - top-5-accuracy: 0.6248 - val_loss: 2.4633 - val_accuracy: 0.3616 - val_top-5-accuracy: 0.6722\n",
            "Epoch 13/20\n",
            "176/176 [==============================] - 149s 845ms/step - loss: 2.6080 - accuracy: 0.3297 - top-5-accuracy: 0.6456 - val_loss: 2.3821 - val_accuracy: 0.3788 - val_top-5-accuracy: 0.6928\n",
            "Epoch 14/20\n",
            "176/176 [==============================] - 149s 845ms/step - loss: 2.5212 - accuracy: 0.3430 - top-5-accuracy: 0.6666 - val_loss: 2.3311 - val_accuracy: 0.3904 - val_top-5-accuracy: 0.7004\n",
            "Epoch 15/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 2.4635 - accuracy: 0.3605 - top-5-accuracy: 0.6757 - val_loss: 2.3031 - val_accuracy: 0.3986 - val_top-5-accuracy: 0.7062\n",
            "Epoch 16/20\n",
            "176/176 [==============================] - 149s 845ms/step - loss: 2.3904 - accuracy: 0.3736 - top-5-accuracy: 0.6913 - val_loss: 2.2661 - val_accuracy: 0.4028 - val_top-5-accuracy: 0.7110\n",
            "Epoch 17/20\n",
            "176/176 [==============================] - 149s 845ms/step - loss: 2.3292 - accuracy: 0.3893 - top-5-accuracy: 0.7073 - val_loss: 2.1566 - val_accuracy: 0.4314 - val_top-5-accuracy: 0.7374\n",
            "Epoch 18/20\n",
            "176/176 [==============================] - 148s 840ms/step - loss: 2.2643 - accuracy: 0.4018 - top-5-accuracy: 0.7180 - val_loss: 2.1633 - val_accuracy: 0.4292 - val_top-5-accuracy: 0.7442\n",
            "Epoch 19/20\n",
            "176/176 [==============================] - 149s 844ms/step - loss: 2.2052 - accuracy: 0.4155 - top-5-accuracy: 0.7336 - val_loss: 2.0713 - val_accuracy: 0.4454 - val_top-5-accuracy: 0.7582\n",
            "Epoch 20/20\n",
            "176/176 [==============================] - 149s 846ms/step - loss: 2.1563 - accuracy: 0.4262 - top-5-accuracy: 0.7418 - val_loss: 2.0494 - val_accuracy: 0.4470 - val_top-5-accuracy: 0.7612\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 2.0184 - accuracy: 0.4592 - top-5-accuracy: 0.7622\n",
            "test accuracy: 45.92\n",
            "test top 5 accuracy: 76.22\n",
            "training - SPT: False, LSA: True, MASKING: True, TRAIN_TAU: False\n",
            "Epoch 1/20\n",
            "176/176 [==============================] - 168s 878ms/step - loss: 4.5214 - accuracy: 0.0352 - top-5-accuracy: 0.1383 - val_loss: 3.9966 - val_accuracy: 0.0924 - val_top-5-accuracy: 0.2940\n",
            "Epoch 2/20\n",
            "176/176 [==============================] - 153s 868ms/step - loss: 4.0220 - accuracy: 0.0821 - top-5-accuracy: 0.2663 - val_loss: 3.6312 - val_accuracy: 0.1580 - val_top-5-accuracy: 0.4096\n",
            "Epoch 3/20\n",
            "176/176 [==============================] - 153s 868ms/step - loss: 3.7822 - accuracy: 0.1181 - top-5-accuracy: 0.3406 - val_loss: 3.4562 - val_accuracy: 0.1792 - val_top-5-accuracy: 0.4492\n",
            "Epoch 4/20\n",
            "176/176 [==============================] - 153s 868ms/step - loss: 3.6183 - accuracy: 0.1448 - top-5-accuracy: 0.3906 - val_loss: 3.2799 - val_accuracy: 0.2134 - val_top-5-accuracy: 0.4960\n",
            "Epoch 5/20\n",
            "176/176 [==============================] - 153s 868ms/step - loss: 3.4777 - accuracy: 0.1685 - top-5-accuracy: 0.4284 - val_loss: 3.1490 - val_accuracy: 0.2444 - val_top-5-accuracy: 0.5282\n",
            "Epoch 6/20\n",
            "176/176 [==============================] - 153s 867ms/step - loss: 3.3601 - accuracy: 0.1906 - top-5-accuracy: 0.4622 - val_loss: 3.0091 - val_accuracy: 0.2592 - val_top-5-accuracy: 0.5644\n",
            "Epoch 7/20\n",
            "176/176 [==============================] - 153s 868ms/step - loss: 3.2337 - accuracy: 0.2132 - top-5-accuracy: 0.4935 - val_loss: 2.9256 - val_accuracy: 0.2764 - val_top-5-accuracy: 0.5778\n",
            "Epoch 8/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 3.1276 - accuracy: 0.2322 - top-5-accuracy: 0.5195 - val_loss: 2.7869 - val_accuracy: 0.2978 - val_top-5-accuracy: 0.6066\n",
            "Epoch 9/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 3.0251 - accuracy: 0.2503 - top-5-accuracy: 0.5482 - val_loss: 2.7304 - val_accuracy: 0.3080 - val_top-5-accuracy: 0.6178\n",
            "Epoch 10/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 2.9450 - accuracy: 0.2687 - top-5-accuracy: 0.5671 - val_loss: 2.6039 - val_accuracy: 0.3398 - val_top-5-accuracy: 0.6500\n",
            "Epoch 11/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 2.8388 - accuracy: 0.2851 - top-5-accuracy: 0.5926 - val_loss: 2.5498 - val_accuracy: 0.3480 - val_top-5-accuracy: 0.6522\n",
            "Epoch 12/20\n",
            "176/176 [==============================] - 152s 866ms/step - loss: 2.7463 - accuracy: 0.3071 - top-5-accuracy: 0.6128 - val_loss: 2.4836 - val_accuracy: 0.3554 - val_top-5-accuracy: 0.6718\n",
            "Epoch 13/20\n",
            "176/176 [==============================] - 153s 867ms/step - loss: 2.6547 - accuracy: 0.3218 - top-5-accuracy: 0.6343 - val_loss: 2.4554 - val_accuracy: 0.3616 - val_top-5-accuracy: 0.6746\n",
            "Epoch 14/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 2.5702 - accuracy: 0.3385 - top-5-accuracy: 0.6520 - val_loss: 2.3560 - val_accuracy: 0.3822 - val_top-5-accuracy: 0.7044\n",
            "Epoch 15/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 2.5234 - accuracy: 0.3499 - top-5-accuracy: 0.6651 - val_loss: 2.3274 - val_accuracy: 0.3924 - val_top-5-accuracy: 0.7074\n",
            "Epoch 16/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 2.4394 - accuracy: 0.3647 - top-5-accuracy: 0.6831 - val_loss: 2.2606 - val_accuracy: 0.4068 - val_top-5-accuracy: 0.7088\n",
            "Epoch 17/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 2.3869 - accuracy: 0.3771 - top-5-accuracy: 0.6930 - val_loss: 2.1998 - val_accuracy: 0.4192 - val_top-5-accuracy: 0.7282\n",
            "Epoch 18/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 2.3189 - accuracy: 0.3911 - top-5-accuracy: 0.7096 - val_loss: 2.1431 - val_accuracy: 0.4248 - val_top-5-accuracy: 0.7444\n",
            "Epoch 19/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 2.2536 - accuracy: 0.4044 - top-5-accuracy: 0.7209 - val_loss: 2.1089 - val_accuracy: 0.4370 - val_top-5-accuracy: 0.7444\n",
            "Epoch 20/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 2.2057 - accuracy: 0.4175 - top-5-accuracy: 0.7317 - val_loss: 2.0797 - val_accuracy: 0.4462 - val_top-5-accuracy: 0.7558\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 2.0497 - accuracy: 0.4499 - top-5-accuracy: 0.7573\n",
            "test accuracy: 44.99\n",
            "test top 5 accuracy: 75.73\n",
            "training - SPT: False, LSA: True, MASKING: True, TRAIN_TAU: True\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "176/176 [==============================] - 168s 873ms/step - loss: 4.5358 - accuracy: 0.0337 - top-5-accuracy: 0.1314 - val_loss: 4.0864 - val_accuracy: 0.0910 - val_top-5-accuracy: 0.2572\n",
            "Epoch 2/20\n",
            "176/176 [==============================] - 152s 864ms/step - loss: 4.0619 - accuracy: 0.0772 - top-5-accuracy: 0.2542 - val_loss: 3.6967 - val_accuracy: 0.1380 - val_top-5-accuracy: 0.3690\n",
            "Epoch 3/20\n",
            "176/176 [==============================] - 152s 863ms/step - loss: 3.8365 - accuracy: 0.1093 - top-5-accuracy: 0.3218 - val_loss: 3.4750 - val_accuracy: 0.1776 - val_top-5-accuracy: 0.4332\n",
            "Epoch 4/20\n",
            "176/176 [==============================] - 152s 864ms/step - loss: 3.6696 - accuracy: 0.1378 - top-5-accuracy: 0.3723 - val_loss: 3.3370 - val_accuracy: 0.1936 - val_top-5-accuracy: 0.4714\n",
            "Epoch 5/20\n",
            "176/176 [==============================] - 152s 864ms/step - loss: 3.5100 - accuracy: 0.1626 - top-5-accuracy: 0.4201 - val_loss: 3.1846 - val_accuracy: 0.2236 - val_top-5-accuracy: 0.5158\n",
            "Epoch 6/20\n",
            "176/176 [==============================] - 152s 864ms/step - loss: 3.3938 - accuracy: 0.1843 - top-5-accuracy: 0.4541 - val_loss: 3.0394 - val_accuracy: 0.2568 - val_top-5-accuracy: 0.5538\n",
            "Epoch 7/20\n",
            "176/176 [==============================] - 152s 864ms/step - loss: 3.2518 - accuracy: 0.2107 - top-5-accuracy: 0.4879 - val_loss: 2.9417 - val_accuracy: 0.2754 - val_top-5-accuracy: 0.5736\n",
            "Epoch 8/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 3.1403 - accuracy: 0.2298 - top-5-accuracy: 0.5190 - val_loss: 2.7807 - val_accuracy: 0.2966 - val_top-5-accuracy: 0.6070\n",
            "Epoch 9/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 3.0469 - accuracy: 0.2458 - top-5-accuracy: 0.5411 - val_loss: 2.7334 - val_accuracy: 0.3086 - val_top-5-accuracy: 0.6156\n",
            "Epoch 10/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 2.9289 - accuracy: 0.2671 - top-5-accuracy: 0.5702 - val_loss: 2.6222 - val_accuracy: 0.3222 - val_top-5-accuracy: 0.6416\n",
            "Epoch 11/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 2.8301 - accuracy: 0.2840 - top-5-accuracy: 0.5936 - val_loss: 2.5997 - val_accuracy: 0.3314 - val_top-5-accuracy: 0.6444\n",
            "Epoch 12/20\n",
            "176/176 [==============================] - 152s 865ms/step - loss: 2.7423 - accuracy: 0.3025 - top-5-accuracy: 0.6145 - val_loss: 2.4807 - val_accuracy: 0.3550 - val_top-5-accuracy: 0.6722\n",
            "Epoch 13/20\n",
            "176/176 [==============================] - 152s 864ms/step - loss: 2.6534 - accuracy: 0.3223 - top-5-accuracy: 0.6358 - val_loss: 2.4182 - val_accuracy: 0.3742 - val_top-5-accuracy: 0.6836\n",
            "Epoch 14/20\n",
            " 83/176 [=============>................] - ETA: 1:16 - loss: 2.5763 - accuracy: 0.3347 - top-5-accuracy: 0.6508"
          ]
        }
      ],
      "source": [
        "modes = [('F', 'F', 'F', 'F'),\n",
        "         ('F', 'T', 'F', 'T'),\n",
        "         ('F', 'T', 'T', 'F'),\n",
        "         ('F', 'T', 'T', 'T'),\n",
        "         ('T', 'F', 'F', 'F'),\n",
        "         ('T', 'T', 'T', 'T')]\n",
        "\n",
        "def to_flag(flag):\n",
        "  if flag == 'T':\n",
        "    return True\n",
        "  elif flag == 'F':\n",
        "    return False\n",
        "  else:\n",
        "    return 'invalid'\n",
        "\n",
        "for mode in modes:\n",
        "  flags = [to_flag(flag) for flag in mode]\n",
        "\n",
        "  model = create_ViT(SPT=flags[0], LSA=flags[1], MASKING=flags[2], TRAIN_TAU=flags[3])\n",
        "  history = run(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PLCIGNEkh5bP"
      },
      "id": "PLCIGNEkh5bP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Miscellaneous",
      "language": "python",
      "name": "miscellaneous"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "run.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}